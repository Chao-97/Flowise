{
    "description": "Phi-2 是一个拥有27 亿个参数的 Transformer。它使用与Phi-1.5相同的数据源进行训练，并使用由各种 NLP 合成文本和过滤网站组成的新数据源进行了增强（出于安全性和教育价值）。当根据测试常识、语言理解和逻辑推理的基准进行评估时，Phi-2 在参数少于 130 亿的模型中展示了近乎最先进的性能。"
}
